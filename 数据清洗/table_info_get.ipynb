{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xieyu\\AppData\\Local\\Temp\\ipykernel_27152\\2374144928.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import os \n",
    "# 连接到SQL Server数据库\n",
    "conn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                      'SERVER=192.168.0.141;'\n",
    "                      'DATABASE=MemberCenter;'\n",
    "                      'UID=sa;'\n",
    "                      'PWD=rootroot;')\n",
    "# SQL 查询\n",
    "sql = \"\"\"\n",
    "SELECT TABLE_SCHEMA, TABLE_NAME\n",
    "FROM INFORMATION_SCHEMA.TABLES\n",
    "WHERE TABLE_TYPE = 'BASE TABLE' AND TABLE_NAME not LIKE '%temp%'\n",
    "\"\"\"\n",
    "# 将查询结果读取到DataFrame中\n",
    "df = pd.read_sql_query(sql, conn)\n",
    "# 关闭连接\n",
    "conn.close()\n",
    "table_names = df['TABLE_NAME'].tolist()\n",
    "# 连接到SQL Server数据库\n",
    "conn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                      'SERVER=192.168.0.141;'\n",
    "                      'DATABASE=MemberCenter;'\n",
    "                      'UID=sa;'\n",
    "                      'PWD=rootroot;')\n",
    "# 创建一个游标对象\n",
    "cursor = conn.cursor()\n",
    "# 获取数据库中所有的表名\n",
    "table_names = []\n",
    "# 读取member_data文件夹中的所有文件名\n",
    "exist_tables = []\n",
    "file_names = os.listdir('member_data')\n",
    "# 遍历文件名列表\n",
    "for file_name in file_names:\n",
    "    # 获取文件名中的表名\n",
    "    exist_table = file_name.split('.')[0]\n",
    "    # 将表名添加到列表中\n",
    "    exist_tables.append(exist_table)\n",
    "for row in cursor.tables():\n",
    "    if row.table_type == 'TABLE':\n",
    "        table_names.append(row.table_name)\n",
    "# 除去table_names中在exist_tables中已经存在的表名\n",
    "table_names = list(set(table_names) - set(exist_tables))\n",
    "# 初始化超时表和跑崩表的列表\n",
    "timeout_tables = []\n",
    "failed_tables = []\n",
    "len(table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历所有的表\n",
    "for table_name in table_names:\n",
    "    print('我开始爬取表：', table_name)\n",
    "    # SQL 查询\n",
    "    sql = f\"\"\"\n",
    "            DECLARE @TotalCount INT;\n",
    "            DECLARE @DynamicSQL NVARCHAR(MAX);\n",
    "            DECLARE @ColumnNames NVARCHAR(MAX);\n",
    "            DECLARE @ColumnNamesConverted NVARCHAR(MAX);\n",
    "            -- 获取总行数\n",
    "            SELECT @TotalCount = COUNT(*) FROM {table_name};\n",
    "\n",
    "            -- 获取字段名称列表和转换后的字段名称列表\n",
    "            SELECT @ColumnNames = STUFF(\n",
    "                (\n",
    "                    SELECT ', ' + QUOTENAME(COLUMN_NAME)\n",
    "                    FROM INFORMATION_SCHEMA.COLUMNS\n",
    "                    WHERE TABLE_NAME = '{table_name}'\n",
    "                    FOR XML PATH('')\n",
    "                ), 1, 2, '');\n",
    "\n",
    "            SELECT @ColumnNamesConverted = STUFF(\n",
    "                (\n",
    "                    SELECT ', CONVERT(NVARCHAR(MAX), ' + QUOTENAME(COLUMN_NAME) + ') AS ' + QUOTENAME(COLUMN_NAME)\n",
    "                    FROM INFORMATION_SCHEMA.COLUMNS\n",
    "                    WHERE TABLE_NAME = '{table_name}'\n",
    "                    FOR XML PATH('')\n",
    "                ), 1, 2, '');\n",
    "\n",
    "            -- 动态构造查询语句\n",
    "            SET @DynamicSQL = N'\n",
    "                WITH ValueCounts AS (\n",
    "                    SELECT \n",
    "                        COLUMN_NAME,\n",
    "                        Value,\n",
    "                        COUNT(*) AS ValueCount\n",
    "                    FROM \n",
    "                        (SELECT ' + @ColumnNamesConverted + ' FROM {table_name}) AS ConvertedData\n",
    "                        UNPIVOT\n",
    "                        (\n",
    "                            Value FOR COLUMN_NAME IN\n",
    "                            (' + @ColumnNames + ')\n",
    "                        ) AS UnpivotedData\n",
    "                    WHERE\n",
    "                        Value IS NOT NULL\n",
    "                    GROUP BY\n",
    "                        COLUMN_NAME, Value\n",
    "                ), GroupedCounts AS (\n",
    "                    SELECT \n",
    "                        COLUMN_NAME,\n",
    "                        SUM(ValueCount) AS NonNullCount,\n",
    "                        COUNT(Value) AS DistinctValueCount,\n",
    "                        STUFF((\n",
    "                            SELECT '', '' +  Value\n",
    "                            FROM ValueCounts AS InnerValueCounts\n",
    "                            WHERE InnerValueCounts.COLUMN_NAME = OuterValueCounts.COLUMN_NAME\n",
    "                            FOR XML PATH('''')\n",
    "                        ), 1, 2, '''') AS DistinctValues\n",
    "                    FROM\n",
    "                        ValueCounts AS OuterValueCounts\n",
    "                    GROUP BY\n",
    "                        COLUMN_NAME\n",
    "                ), ColumnTypes AS (\n",
    "                    SELECT \n",
    "                        COLUMN_NAME,\n",
    "                        DATA_TYPE AS FieldType\n",
    "                    FROM \n",
    "                        INFORMATION_SCHEMA.COLUMNS\n",
    "                    WHERE \n",
    "                        TABLE_NAME = ''{table_name}''\n",
    "                )\n",
    "                SELECT \n",
    "                    ''{table_name}'' AS TableName,\n",
    "                    gc.COLUMN_NAME AS FieldName,\n",
    "                    ct.FieldType,\n",
    "                    gc.NonNullCount * 100.0 / ' + CAST(@TotalCount AS NVARCHAR) + ' AS NonNullPercentage,\n",
    "                    gc.DistinctValueCount,\n",
    "                    CASE \n",
    "                        WHEN gc.DistinctValueCount <= 120 THEN gc.DistinctValues\n",
    "                        ELSE ''大于120种类''\n",
    "                    END AS DistinctValues\n",
    "                FROM \n",
    "                    GroupedCounts AS gc\n",
    "                    JOIN ColumnTypes AS ct ON gc.COLUMN_NAME = ct.COLUMN_NAME;\n",
    "            ';\n",
    "\n",
    "            -- 执行动态查询语句\n",
    "            EXEC sp_executesql @DynamicSQL;\n",
    "    \"\"\"\n",
    "    # 执行SQL查询\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        # 获取查询结果\n",
    "        result = cursor.fetchall()\n",
    "        # 将列表转换为DataFrame\n",
    "        df = pd.DataFrame.from_records(result, columns=['表名', '字段名','字段类型', '非空占比', '唯一值数量','唯一值集合'])\n",
    "        df1 = df\n",
    "        # 计算非空占比不是100%的字段\n",
    "        non_100_percent_fields = df1[df1['非空占比'] != '100.00%']\n",
    "\n",
    "        # 统计这些字段的数量\n",
    "        num_non_100_percent_fields = len(non_100_percent_fields)\n",
    "        # 整理为一句话并显示结果\n",
    "        fields_list = ', '.join(non_100_percent_fields['字段名'].tolist())\n",
    "        print(f\"共有 {num_non_100_percent_fields} 个字段的非空占比不是100%，这些字段分别是：{fields_list}\")\n",
    "        # 增加一列，用于标记是否为高基数字段\n",
    "        df1['字段分类'] = df1['唯一值数量'].apply(lambda x: '多值变量' if x > 250 else '非多值变量')\n",
    "        # 替换大于50类为略\n",
    "        df1['唯一值集合'] = df1['唯一值集合'].apply(lambda x: '略' if x == '大于250种类' else x)\n",
    "        # 按照非空占比进行排序\n",
    "        df1 = df1.sort_values(by=['字段分类','非空占比','唯一值数量'], ascending=[True,False,False])\n",
    "        # 将非空占比转换为百分数并保留两位小数\n",
    "        df1['非空占比'] = df['非空占比'].apply(lambda x: '{:.2f}%'.format(float(x)))\n",
    "        # 更换列顺序\n",
    "        df1 = df1[['表名','字段分类','字段名','字段类型','非空占比','唯一值数量','唯一值集合']]\n",
    "        # 将结果写入Excel并保存到本地\n",
    "        df1.to_excel(f'./Member_data/{table_name}.xlsx', index=False)\n",
    "    except pyodbc.ProgrammingError as e:\n",
    "        print(f\"表 {table_name} 查询出错，错误信息为：{e}\")\n",
    "        failed_tables.append(table_name)\n",
    "        continue\n",
    "    except :\n",
    "        print(f\"表 {table_name} 查询超时，已跳过\")\n",
    "        timeout_tables.append(table_name)\n",
    "        continue\n",
    "# 关闭游标和连接\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将member_data文件夹中的所有Excel文件合并为一个Excel文件\n",
    "# 获取member_data文件夹中的所有Excel文件\n",
    "import glob\n",
    "file_list = glob.glob('./Member_data/*.xlsx')\n",
    "# 读取所有Excel文件\n",
    "df_list = [pd.read_excel(file) for file in file_list]\n",
    "# 合并所有Excel文件\n",
    "df = pd.concat(df_list)\n",
    "# 将结果写入Excel并保存到本地\n",
    "df.to_excel('./Member_data/Member_data.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
